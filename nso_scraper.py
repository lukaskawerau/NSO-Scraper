from bs4 import BeautifulSoup
import requests
import csv
import re

output = open("stat_sites.csv", 'w')
csv_writer = csv.writer(output)

link = "http://unstats.un.org/unsd/methods/inter-natlinks/sd_natstat.asp"

page = requests.get(link)
soup = BeautifulSoup(page.text, "lxml")

table = soup.find_all("td", class_="content")
continents = table[0].find_all("h3")
asia = table[0].find_all("b")
continents.append(asia[0])
continents.pop(0)

for continent in continents:
    if continent == continents[len(continents)-1]:
        table = continent.previous_element.next_sibling.next
    else:
        table = continent.next_sibling.next
    rows = table.find_all("tr")
    for row in rows:
        country = row.next.next.next
        country = re.sub('<[^<]+?>', '', str(country))  # Strip html tags
        if country == "Â ":  # NONBREAKING SPACE! (Opt + Space) for USA List
            country = "United States"
        links = row.next.next.next_sibling.next.find_all("a")
        if len(links) > 1:
            for l in links:
                link = l["href"]
                name = l.next
                name = " ".join(name.split())
                csv_writer.writerow([country, link, name])
        else:
            link = row.next.next.next_sibling.next.find_all("a")[0]["href"]
            name = row.next.next.next_sibling.next.find_all("a")[0].next
            name = " ".join(name.split())
            csv_writer.writerow([country, link, name])
